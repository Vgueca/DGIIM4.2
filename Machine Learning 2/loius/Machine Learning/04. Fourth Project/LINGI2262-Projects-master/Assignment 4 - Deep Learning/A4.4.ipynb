{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff7544d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "((x_train, y_train), (x_test, y_test)) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train = x_train.reshape((60000, 28, 28, 1))\n",
    "x_test = x_test.reshape((10000, 28, 28, 1))\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0231cf10",
   "metadata": {},
   "source": [
    "Question 1 : A Convolutional Neural Network \n",
    "---\n",
    "\n",
    "In this question, we ask you to build a model closely matching the above picture.\n",
    "\n",
    "The model must have:\n",
    "\n",
    "- **3 convolutional blocks** with a number of filters of respectively $16$, $32$, and $64$; **each block containing**:\n",
    "    - A *Conv2D* layer with a *ReLU* activation.\n",
    "    - A Max Pooling layer ($2,2$ pool size)\n",
    "- A dense layer with $28$ hidden units.\n",
    "- A dense output layer with a softmax activation.\n",
    "\n",
    "You are free to play with the meta-parameters of each of these layers, as long as you respect this structure.\n",
    "\n",
    "Implement you neural network in the variable *model*. Just define and compile the network, don't fit it on the training data (your submission will likely time out if you do!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb823c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = (8, 8)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, kernel_size=kernel_size, padding='same', activation='relu', input_shape=(28, 28, 1)), \n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2), \n",
    "    \n",
    "    tf.keras.layers.Conv2D(32, kernel_size=kernel_size, padding='same', activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2), \n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, kernel_size=kernel_size, padding='same', activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2), \n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(28, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "    \n",
    "], name='convolutional_net')\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d88a90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "235/235 [==============================] - 14s 39ms/step - loss: 2.5910 - accuracy: 0.4890 - val_loss: 0.5249 - val_accuracy: 0.8241\n",
      "Epoch 2/30\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.4294 - accuracy: 0.8515 - val_loss: 0.3933 - val_accuracy: 0.8642\n",
      "Epoch 3/30\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.3447 - accuracy: 0.8778 - val_loss: 0.3533 - val_accuracy: 0.8734\n",
      "Epoch 4/30\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3059 - accuracy: 0.8907 - val_loss: 0.3269 - val_accuracy: 0.8856\n",
      "Epoch 5/30\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2722 - accuracy: 0.9034 - val_loss: 0.3463 - val_accuracy: 0.8851\n",
      "Epoch 6/30\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2465 - accuracy: 0.9118 - val_loss: 0.3285 - val_accuracy: 0.8856\n",
      "Epoch 7/30\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2282 - accuracy: 0.9175 - val_loss: 0.3283 - val_accuracy: 0.8858\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 8/30\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.1854 - accuracy: 0.9344 - val_loss: 0.2902 - val_accuracy: 0.8979\n",
      "Epoch 9/30\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.1674 - accuracy: 0.9417 - val_loss: 0.2898 - val_accuracy: 0.8980\n",
      "Epoch 10/30\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.1581 - accuracy: 0.9441 - val_loss: 0.2930 - val_accuracy: 0.8964\n",
      "Epoch 11/30\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.1562 - accuracy: 0.9454 - val_loss: 0.2934 - val_accuracy: 0.9018\n",
      "Epoch 12/30\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.1466 - accuracy: 0.9484 - val_loss: 0.2881 - val_accuracy: 0.9018\n",
      "Epoch 13/30\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.1422 - accuracy: 0.9503 - val_loss: 0.2923 - val_accuracy: 0.9002\n",
      "Epoch 14/30\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.1384 - accuracy: 0.9522 - val_loss: 0.2954 - val_accuracy: 0.9013\n",
      "Epoch 15/30\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.1338 - accuracy: 0.9542 - val_loss: 0.2946 - val_accuracy: 0.9025\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 16/30\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.1229 - accuracy: 0.9582 - val_loss: 0.2930 - val_accuracy: 0.9036\n",
      "Epoch 17/30\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.1185 - accuracy: 0.9597 - val_loss: 0.2931 - val_accuracy: 0.9030\n",
      "Epoch 18/30\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.1152 - accuracy: 0.9618 - val_loss: 0.2940 - val_accuracy: 0.9029\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 19/30\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.1159 - accuracy: 0.9618 - val_loss: 0.2930 - val_accuracy: 0.9032\n",
      "Epoch 20/30\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.1172 - accuracy: 0.9606 - val_loss: 0.2930 - val_accuracy: 0.9033\n",
      "Epoch 21/30\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.1151 - accuracy: 0.9616 - val_loss: 0.2928 - val_accuracy: 0.9035\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 22/30\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.1159 - accuracy: 0.9615 - val_loss: 0.2928 - val_accuracy: 0.9036\n",
      "Epoch 23/30\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.1161 - accuracy: 0.9620 - val_loss: 0.2928 - val_accuracy: 0.9033\n",
      "Epoch 24/30\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.1158 - accuracy: 0.9617 - val_loss: 0.2929 - val_accuracy: 0.9034\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 25/30\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.1153 - accuracy: 0.9617 - val_loss: 0.2929 - val_accuracy: 0.9034\n",
      "Epoch 26/30\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.1158 - accuracy: 0.9625 - val_loss: 0.2929 - val_accuracy: 0.9034\n",
      "Epoch 27/30\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.1154 - accuracy: 0.9623 - val_loss: 0.2929 - val_accuracy: 0.9034\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 28/30\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.1146 - accuracy: 0.9627 - val_loss: 0.2929 - val_accuracy: 0.9034\n",
      "Epoch 29/30\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.1182 - accuracy: 0.9608 - val_loss: 0.2929 - val_accuracy: 0.9034\n",
      "Epoch 30/30\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.1194 - accuracy: 0.9605 - val_loss: 0.2929 - val_accuracy: 0.9034\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n"
     ]
    }
   ],
   "source": [
    "def prepare_dataset(X, y, batch_size, shuffle=True, augment=True):\n",
    "    augmented_args = dict(\n",
    "        rotation_range = 8,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        shear_range = 0.3,# shear angle in counter-clockwise direction in degrees  \n",
    "        width_shift_range=0.08,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.08,  # randomly shift images vertically (fraction of total height)\n",
    "        vertical_flip=True # randomly flip images\n",
    "    \n",
    "        # horizontal_flip=True,\n",
    "        # vertical_flip=True,\n",
    "        # rotation_range=20,\n",
    "        # width_shift_range=0.2,\n",
    "        # height_shift_range=0.2\n",
    "        )\n",
    "    args = {} if not augment else augmented_args\n",
    "    \n",
    "    ds = tf.keras.preprocessing.image.ImageDataGenerator(**args).flow(X, y, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return ds\n",
    "\n",
    "train_ds = prepare_dataset(x_train, y_train, 256, augment=False)\n",
    "\n",
    "callbacks = [\n",
    "    # tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(patience=3, verbose=True)\n",
    "    # tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "model.save(f\"./models/{model.name}.model\", save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066bbaed",
   "metadata": {},
   "source": [
    "Question 3: Multiple choice \n",
    "---\n",
    "\n",
    "Select all valid affirmations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86197200",
   "metadata": {},
   "source": [
    "- [ ] The number of filters of a convolutional layer does not influence its output shape.\n",
    "- [ ] Reducing a lot the number of hidden units (e.g. down to 5 units) of the last layer before the output layer significantly decreases the achievable test accuracy (drop of 5% or more).\n",
    "- [ ] Increasing or decreasing the number of convolutional blocks (yet, such number should be always >=1) of the network of Q1 and Q2 significantly influences the achievable test accuracy (drop or gain of 5% or more).\n",
    "- [x] Increasing the pool size of a max pooling layer decreases the size of the output of that layer.\n",
    "- [x] Using a pool size of (3,3) instead of (2,2) in the network of Q1 and Q2 produces 64 images of 1 pixel (at the output of the last convolutional block).\n",
    "- [x] Increasing a lot the number of hidden units (e.g. up to 1000 units) of the last layer before the output layer significantly increases the achievable test accuracy (gain of 5% or more).\n",
    "- [ ] Using a tanh activation function instead of relu significantly decreases (drop of 5% or more) the achievable test accuracy.\n",
    "- [x] A high regularization on the weights of a layer increases overfitting.\n",
    "- [ ] Having 64 images of 1 pixel at the output of the last convolutional block would prevent any learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ingi2262",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
