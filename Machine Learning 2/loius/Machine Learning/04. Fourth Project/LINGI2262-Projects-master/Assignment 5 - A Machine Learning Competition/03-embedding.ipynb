{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d49a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "import numpy as np\n",
    "from os.path import join  \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.distribute import MirroredStrategy, OneDeviceStrategy\n",
    "\n",
    "from utils import *\n",
    "\n",
    "datasets = join(os.getcwd(), \"datasets\")\n",
    "preprocessed_datasets = join(datasets, \"preprocessed\")\n",
    "\n",
    "X_all, y_all, X_test = pickle.load(open(join(preprocessed_datasets, \"cleaned_separated.pickle\"), 'rb'))\n",
    "\n",
    "strategy = OneDeviceStrategy(\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7482ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_tuple_split(X, y, train_size, seed=None):\n",
    "    def apply_tuple_split(X, split):\n",
    "        train, test = [], []\n",
    "        for x in X:\n",
    "            train.append(x[:split])\n",
    "            test.append(x[split:])\n",
    "        return tuple(train), tuple(test)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    indices_ = np.arange(len(y))\n",
    "    np.random.shuffle(indices_)\n",
    "    \n",
    "    splitter_indice = int(len(y) * train_size)\n",
    "    train_indices, test_indices = np.split(indices_, [splitter_indice])\n",
    "    \n",
    "    X_train, X_test = apply_tuple_split(X, splitter_indice)\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_tuple_split(X_all, y_all, .75, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cea42c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 6, 128)       4480        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 6, 1)         129         embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1306624)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 6)            0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1306630)      0           input_1[0][0]                    \n",
      "                                                                 flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1306631     concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,311,240\n",
      "Trainable params: 1,311,240\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    \n",
    "    conv_len, vp_len = X_train[0].shape[-1], X_train[1].shape[-1]\n",
    "    vocab_dim = int(np.unique(np.r_[X_train[1], X_test[1]]).max())+1\n",
    "    \n",
    "    conv_input = tf.keras.layers.Input(shape=(conv_len,))\n",
    "    \n",
    "    vp_input = tf.keras.layers.Input(shape=(vp_len,))\n",
    "    embedded = tf.keras.layers.Embedding(vocab_dim, 128, input_length=vp_len)(vp_input)\n",
    "    dense_emb = tf.keras.layers.Dense(1)(embedded)\n",
    "    flatten_emb = tf.keras.layers.Flatten()(dense_emb)\n",
    "    \n",
    "    \n",
    "    concat = tf.keras.layers.Concatenate()([conv_input, flatten_emb])\n",
    "    \n",
    "    output = tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.L1(0.01), activation='sigmoid')(concat)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[conv_input, vp_input], outputs=output)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=1e-3),\n",
    "        metrics=[bcr, p1, p2, m1, m2, \"accuracy\"]\n",
    "    )\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_bcr', factor=.5, patience=10, verbose=2),\n",
    "    BCREarlyStopping(patience=30, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f84c00e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - ETA: 2s - loss: 18.3373 - bcr: 0.4473 - p1: 0.8205 - p2: 0.0741 - m1: 39.0000 - m2: 81.0000 - accuracy: 0.316 - ETA: 0s - loss: 548.1427 - bcr: 0.4605 - p1: 0.6154 - p2: 0.3056 - m1: 38.2500 - m2: 79.5000 - accuracy: 0.40 - 6s 3s/step - loss: 724.7445 - bcr: 0.4649 - p1: 0.5470 - p2: 0.3827 - m1: 38.0000 - m2: 79.0000 - accuracy: 0.4317 - val_loss: 4276.5908 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romaingrx/Nextcloud/EPL/Q8/Cours/LINGI2262 - Machine Learning/LINGI2262-Projects/Assignment 5 - A Machine Learning Competition/utils.py:105: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return bcr - bcr_delta * (1 - np.exp(-bcr_delta / sigma))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best p value : 0.4472934603691101\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 2235.0940 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 33.0000 - m2: 87.0000 - accuracy: 0.725 - ETA: 0s - loss: 2365.2659 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 35.2500 - m2: 82.5000 - accuracy: 0.700 - 1s 467ms/step - loss: 2408.6565 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 36.0000 - m2: 81.0000 - accuracy: 0.6919 - val_loss: 2581.7910 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romaingrx/Nextcloud/EPL/Q8/Cours/LINGI2262 - Machine Learning/LINGI2262-Projects/Assignment 5 - A Machine Learning Competition/utils.py:105: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return bcr - bcr_delta * (1 - np.exp(-bcr_delta / sigma))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 1540.2231 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 38.0000 - m2: 82.0000 - accuracy: 0.683 - ETA: 0s - loss: 1297.9147 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 37.7500 - m2: 80.0000 - accuracy: 0.679 - 1s 451ms/step - loss: 1217.1452 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 37.6667 - m2: 79.3333 - accuracy: 0.6780 - val_loss: 1109.2920 - val_bcr: 0.5000 - val_p1: 1.0000 - val_p2: 0.0000e+00 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5256\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 1527.2213 - bcr: 0.5000 - p1: 1.0000 - p2: 0.0000e+00 - m1: 41.0000 - m2: 79.0000 - accuracy: 0.341 - ETA: 0s - loss: 1680.3083 - bcr: 0.5000 - p1: 1.0000 - p2: 0.0000e+00 - m1: 39.2500 - m2: 78.5000 - accuracy: 0.333 - 1s 460ms/step - loss: 1731.3373 - bcr: 0.5000 - p1: 1.0000 - p2: 0.0000e+00 - m1: 38.6667 - m2: 78.3333 - accuracy: 0.3303 - val_loss: 914.9709 - val_bcr: 0.5000 - val_p1: 1.0000 - val_p2: 0.0000e+00 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5256\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 1290.7990 - bcr: 0.5000 - p1: 1.0000 - p2: 0.0000e+00 - m1: 39.0000 - m2: 81.0000 - accuracy: 0.325 - ETA: 0s - loss: 1018.4598 - bcr: 0.5000 - p1: 0.7500 - p2: 0.2500 - m1: 38.2500 - m2: 79.5000 - accuracy: 0.4093    - 1s 474ms/step - loss: 927.6801 - bcr: 0.5000 - p1: 0.6667 - p2: 0.3333 - m1: 38.0000 - m2: 79.0000 - accuracy: 0.4373 - val_loss: 1036.1910 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 601.0212 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 38.0000 - m2: 82.0000 - accuracy: 0.68 - ETA: 0s - loss: 654.9505 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 37.7500 - m2: 80.0000 - accuracy: 0.67 - 1s 484ms/step - loss: 672.9269 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 37.6667 - m2: 79.3333 - accuracy: 0.6780 - val_loss: 1255.0131 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 786.1952 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 41.0000 - m2: 79.0000 - accuracy: 0.65 - ETA: 0s - loss: 703.7325 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 39.2500 - m2: 78.5000 - accuracy: 0.66 - 1s 480ms/step - loss: 676.2450 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 38.6667 - m2: 78.3333 - accuracy: 0.6697 - val_loss: 106.9339 - val_bcr: 0.5109 - val_p1: 0.0488 - val_p2: 0.9730 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4872\n",
      "New best p value : 0.49567568780930626\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 36.6396 - bcr: 0.6081 - p1: 0.2162 - p2: 1.0000 - m1: 37.0000 - m2: 83.0000 - accuracy: 0.758 - ETA: 0s - loss: 256.0737 - bcr: 0.5811 - p1: 0.4122 - p2: 0.7500 - m1: 37.2500 - m2: 80.5000 - accuracy: 0.65 - 1s 509ms/step - loss: 329.2184 - bcr: 0.5721 - p1: 0.4775 - p2: 0.6667 - m1: 37.3333 - m2: 79.6667 - accuracy: 0.6251 - val_loss: 817.6198 - val_bcr: 0.5000 - val_p1: 1.0000 - val_p2: 0.0000e+00 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5256\n",
      "New best p value : 0.5\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 1206.1560 - bcr: 0.5000 - p1: 1.0000 - p2: 0.0000e+00 - m1: 33.0000 - m2: 87.0000 - accuracy: 0.275 - ETA: 0s - loss: 997.8078 - bcr: 0.5000 - p1: 1.0000 - p2: 0.0000e+00 - m1: 35.2500 - m2: 82.5000 - accuracy: 0.299 - 1s 510ms/step - loss: 928.3584 - bcr: 0.5000 - p1: 1.0000 - p2: 0.0000e+00 - m1: 36.0000 - m2: 81.0000 - accuracy: 0.3081 - val_loss: 719.1054 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 363.7325 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 36.0000 - m2: 84.0000 - accuracy: 0.70 - ETA: 0s - loss: 489.0672 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 36.7500 - m2: 81.0000 - accuracy: 0.68 - 1s 466ms/step - loss: 530.8455 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 37.0000 - m2: 80.0000 - accuracy: 0.6835 - val_loss: 1687.6967 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 1014.0958 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 40.0000 - m2: 80.0000 - accuracy: 0.666 - ETA: 0s - loss: 999.3651 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 38.7500 - m2: 79.0000 - accuracy: 0.671 - 1s 476ms/step - loss: 994.4549 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 38.3333 - m2: 78.6667 - accuracy: 0.6724 - val_loss: 1372.2026 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 672.1281 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 33.0000 - m2: 87.0000 - accuracy: 0.72 - ETA: 0s - loss: 688.1419 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 35.2500 - m2: 82.5000 - accuracy: 0.70 - 1s 474ms/step - loss: 693.4798 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 36.0000 - m2: 81.0000 - accuracy: 0.6919 - val_loss: 729.0115 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 330.3542 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 33.0000 - m2: 87.0000 - accuracy: 0.72 - ETA: 0s - loss: 283.2075 - bcr: 0.5089 - p1: 0.0179 - p2: 1.0000 - m1: 35.2500 - m2: 82.5000 - accuracy: 0.7067   - 1s 498ms/step - loss: 267.4919 - bcr: 0.5119 - p1: 0.0238 - p2: 1.0000 - m1: 36.0000 - m2: 81.0000 - accuracy: 0.7005 - val_loss: 309.4641 - val_bcr: 0.5000 - val_p1: 1.0000 - val_p2: 0.0000e+00 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5256\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 334.3934 - bcr: 0.5063 - p1: 1.0000 - p2: 0.0125 - m1: 40.0000 - m2: 80.0000 - accuracy: 0.34 - ETA: 0s - loss: 415.6803 - bcr: 0.5047 - p1: 1.0000 - p2: 0.0094 - m1: 38.7500 - m2: 79.0000 - accuracy: 0.33 - 1s 498ms/step - loss: 442.7759 - bcr: 0.5042 - p1: 1.0000 - p2: 0.0083 - m1: 38.3333 - m2: 78.6667 - accuracy: 0.3332 - val_loss: 438.6601 - val_bcr: 0.5000 - val_p1: 1.0000 - val_p2: 0.0000e+00 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5256\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 566.5045 - bcr: 0.5000 - p1: 1.0000 - p2: 0.0000e+00 - m1: 36.0000 - m2: 84.0000 - accuracy: 0.30 - ETA: 0s - loss: 450.8439 - bcr: 0.5382 - p1: 1.0000 - p2: 0.0764 - m1: 36.7500 - m2: 81.0000 - accuracy: 0.3600   - 1s 496ms/step - loss: 412.2904 - bcr: 0.5509 - p1: 1.0000 - p2: 0.1019 - m1: 37.0000 - m2: 80.0000 - accuracy: 0.3799 - val_loss: 389.4427 - val_bcr: 0.5122 - val_p1: 0.0244 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4872\n",
      "New best p value : 0.5125062925695922\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 164.8453 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 37.0000 - m2: 83.0000 - accuracy: 0.69 - ETA: 0s - loss: 220.3804 - bcr: 0.5033 - p1: 0.0066 - p2: 1.0000 - m1: 37.2500 - m2: 80.5000 - accuracy: 0.6857   - 1s 485ms/step - loss: 238.8921 - bcr: 0.5044 - p1: 0.0088 - p2: 1.0000 - m1: 37.3333 - m2: 79.6667 - accuracy: 0.6837 - val_loss: 871.4883 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 540.2096 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 44.0000 - m2: 76.0000 - accuracy: 0.63 - ETA: 0s - loss: 504.6131 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 40.7500 - m2: 77.0000 - accuracy: 0.65 - 1s 517ms/step - loss: 492.7476 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 39.6667 - m2: 77.3333 - accuracy: 0.6613 - val_loss: 754.2451 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 378.8537 - bcr: 0.5132 - p1: 0.0263 - p2: 1.0000 - m1: 38.0000 - m2: 82.0000 - accuracy: 0.69 - ETA: 0s - loss: 352.5207 - bcr: 0.5099 - p1: 0.0197 - p2: 1.0000 - m1: 37.7500 - m2: 80.0000 - accuracy: 0.68 - 1s 502ms/step - loss: 343.7431 - bcr: 0.5088 - p1: 0.0175 - p2: 1.0000 - m1: 37.6667 - m2: 79.3333 - accuracy: 0.6837 - val_loss: 203.5854 - val_bcr: 0.4960 - val_p1: 0.0732 - val_p2: 0.9189 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 67.0754 - bcr: 0.6562 - p1: 0.3250 - p2: 0.9875 - m1: 40.0000 - m2: 80.0000 - accuracy: 0.766 - ETA: 0s - loss: 108.1637 - bcr: 0.6238 - p1: 0.4938 - p2: 0.7538 - m1: 38.7500 - m2: 79.0000 - accuracy: 0.66 - 1s 480ms/step - loss: 121.8598 - bcr: 0.6129 - p1: 0.5500 - p2: 0.6759 - m1: 38.3333 - m2: 78.6667 - accuracy: 0.6336 - val_loss: 303.5677 - val_bcr: 0.5135 - val_p1: 1.0000 - val_p2: 0.0270 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "New best p value : 0.5137410135252991\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 310.6262 - bcr: 0.5195 - p1: 1.0000 - p2: 0.0390 - m1: 43.0000 - m2: 77.0000 - accuracy: 0.38 - ETA: 0s - loss: 267.2606 - bcr: 0.5399 - p1: 1.0000 - p2: 0.0799 - m1: 40.2500 - m2: 77.5000 - accuracy: 0.39 - 1s 474ms/step - loss: 252.8055 - bcr: 0.5467 - p1: 1.0000 - p2: 0.0935 - m1: 39.3333 - m2: 77.6667 - accuracy: 0.3991 - val_loss: 243.6328 - val_bcr: 0.4974 - val_p1: 0.0488 - val_p2: 0.9459 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 92.8250 - bcr: 0.5833 - p1: 0.1667 - p2: 1.0000 - m1: 36.0000 - m2: 84.0000 - accuracy: 0.750 - ETA: 0s - loss: 122.0608 - bcr: 0.5689 - p1: 0.1378 - p2: 1.0000 - m1: 36.7500 - m2: 81.0000 - accuracy: 0.73 - 1s 478ms/step - loss: 131.8060 - bcr: 0.5641 - p1: 0.1282 - p2: 1.0000 - m1: 37.0000 - m2: 80.0000 - accuracy: 0.7233 - val_loss: 546.2761 - val_bcr: 0.5122 - val_p1: 0.0244 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4872\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 251.3419 - bcr: 0.5278 - p1: 0.0556 - p2: 1.0000 - m1: 36.0000 - m2: 84.0000 - accuracy: 0.71 - ETA: 0s - loss: 250.6849 - bcr: 0.5240 - p1: 0.0481 - p2: 1.0000 - m1: 36.7500 - m2: 81.0000 - accuracy: 0.70 - 1s 559ms/step - loss: 250.4658 - bcr: 0.5228 - p1: 0.0456 - p2: 1.0000 - m1: 37.0000 - m2: 80.0000 - accuracy: 0.6978 - val_loss: 337.5589 - val_bcr: 0.4987 - val_p1: 0.0244 - val_p2: 0.9730 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 130.8470 - bcr: 0.5395 - p1: 0.0789 - p2: 1.0000 - m1: 38.0000 - m2: 82.0000 - accuracy: 0.70 - ETA: 0s - loss: 107.9134 - bcr: 0.5972 - p1: 0.2281 - p2: 0.9662 - m1: 37.7500 - m2: 80.0000 - accuracy: 0.73 - 1s 533ms/step - loss: 100.2689 - bcr: 0.6164 - p1: 0.2779 - p2: 0.9550 - m1: 37.6667 - m2: 79.3333 - accuracy: 0.7383 - val_loss: 209.4159 - val_bcr: 0.5135 - val_p1: 1.0000 - val_p2: 0.0270 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 191.3973 - bcr: 0.5663 - p1: 1.0000 - p2: 0.1325 - m1: 37.0000 - m2: 83.0000 - accuracy: 0.40 - ETA: 0s - loss: 185.6897 - bcr: 0.5634 - p1: 1.0000 - p2: 0.1268 - m1: 37.2500 - m2: 80.5000 - accuracy: 0.40 - 1s 519ms/step - loss: 183.7871 - bcr: 0.5624 - p1: 1.0000 - p2: 0.1249 - m1: 37.3333 - m2: 79.6667 - accuracy: 0.4046 - val_loss: 111.7977 - val_bcr: 0.4637 - val_p1: 0.1707 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4487\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 32.7075 - bcr: 0.7500 - p1: 0.6500 - p2: 0.8500 - m1: 40.0000 - m2: 80.0000 - accuracy: 0.783 - ETA: 0s - loss: 45.7623 - bcr: 0.7125 - p1: 0.5375 - p2: 0.8875 - m1: 38.7500 - m2: 79.0000 - accuracy: 0.774 - 1s 486ms/step - loss: 50.1139 - bcr: 0.7000 - p1: 0.5000 - p2: 0.9000 - m1: 38.3333 - m2: 78.6667 - accuracy: 0.7719 - val_loss: 375.4272 - val_bcr: 0.5122 - val_p1: 0.0244 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4872\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 146.5999 - bcr: 0.5375 - p1: 0.0750 - p2: 1.0000 - m1: 40.0000 - m2: 80.0000 - accuracy: 0.69 - ETA: 0s - loss: 144.0649 - bcr: 0.5353 - p1: 0.0705 - p2: 1.0000 - m1: 38.7500 - m2: 79.0000 - accuracy: 0.69 - 1s 470ms/step - loss: 143.2200 - bcr: 0.5345 - p1: 0.0690 - p2: 1.0000 - m1: 38.3333 - m2: 78.6667 - accuracy: 0.6952 - val_loss: 186.1362 - val_bcr: 0.4960 - val_p1: 0.0732 - val_p2: 0.9189 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 54.2545 - bcr: 0.6860 - p1: 0.3721 - p2: 1.0000 - m1: 43.0000 - m2: 77.0000 - accuracy: 0.775 - ETA: 0s - loss: 58.9546 - bcr: 0.7076 - p1: 0.5291 - p2: 0.8861 - m1: 40.2500 - m2: 77.5000 - accuracy: 0.751 - 1s 489ms/step - loss: 60.5212 - bcr: 0.7147 - p1: 0.5814 - p2: 0.8481 - m1: 39.3333 - m2: 77.6667 - accuracy: 0.7432 - val_loss: 162.1527 - val_bcr: 0.5162 - val_p1: 0.9512 - val_p2: 0.0811 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "New best p value : 0.5162575177970372\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 115.9846 - bcr: 0.6533 - p1: 1.0000 - p2: 0.3067 - m1: 45.0000 - m2: 75.0000 - accuracy: 0.56 - ETA: 0s - loss: 101.1608 - bcr: 0.6922 - p1: 1.0000 - p2: 0.3843 - m1: 41.2500 - m2: 76.5000 - accuracy: 0.60 - 1s 544ms/step - loss: 96.2195 - bcr: 0.7051 - p1: 1.0000 - p2: 0.4102 - m1: 40.0000 - m2: 77.0000 - accuracy: 0.6160 - val_loss: 189.6994 - val_bcr: 0.4960 - val_p1: 0.0732 - val_p2: 0.9189 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 50.1828 - bcr: 0.6400 - p1: 0.2927 - p2: 0.9873 - m1: 41.0000 - m2: 79.0000 - accuracy: 0.750 - ETA: 0s - loss: 60.2430 - bcr: 0.6271 - p1: 0.2636 - p2: 0.9905 - m1: 39.2500 - m2: 78.5000 - accuracy: 0.749 - 1s 539ms/step - loss: 63.5964 - bcr: 0.6228 - p1: 0.2539 - p2: 0.9916 - m1: 38.6667 - m2: 78.3333 - accuracy: 0.7493 - val_loss: 263.9057 - val_bcr: 0.5122 - val_p1: 0.0244 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4872\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 88.0255 - bcr: 0.5811 - p1: 0.1622 - p2: 1.0000 - m1: 37.0000 - m2: 83.0000 - accuracy: 0.741 - ETA: 0s - loss: 74.8372 - bcr: 0.6380 - p1: 0.2795 - p2: 0.9966 - m1: 37.2500 - m2: 80.5000 - accuracy: 0.771 - 1s 512ms/step - loss: 70.4412 - bcr: 0.6570 - p1: 0.3186 - p2: 0.9954 - m1: 37.3333 - m2: 79.6667 - accuracy: 0.7811 - val_loss: 90.5461 - val_bcr: 0.4901 - val_p1: 0.6829 - val_p2: 0.2973 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5000\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 47.3857 - bcr: 0.7781 - p1: 0.9773 - p2: 0.5789 - m1: 44.0000 - m2: 76.0000 - accuracy: 0.725 - ETA: 0s - loss: 50.0176 - bcr: 0.7836 - p1: 0.9830 - p2: 0.5842 - m1: 40.7500 - m2: 77.0000 - accuracy: 0.721 - 1s 495ms/step - loss: 50.8949 - bcr: 0.7854 - p1: 0.9848 - p2: 0.5860 - m1: 39.6667 - m2: 77.3333 - accuracy: 0.7207 - val_loss: 84.3810 - val_bcr: 0.5020 - val_p1: 0.4634 - val_p2: 0.5405 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5000\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 28.2332 - bcr: 0.8578 - p1: 0.8889 - p2: 0.8267 - m1: 45.0000 - m2: 75.0000 - accuracy: 0.850 - ETA: 0s - loss: 29.9390 - bcr: 0.8220 - p1: 0.7833 - p2: 0.8607 - m1: 41.2500 - m2: 76.5000 - accuracy: 0.844 - 1s 518ms/step - loss: 30.5076 - bcr: 0.8101 - p1: 0.7481 - p2: 0.8721 - m1: 40.0000 - m2: 77.0000 - accuracy: 0.8432 - val_loss: 197.6304 - val_bcr: 0.4960 - val_p1: 0.0732 - val_p2: 0.9189 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 50.6412 - bcr: 0.6429 - p1: 0.2857 - p2: 1.0000 - m1: 35.0000 - m2: 85.0000 - accuracy: 0.791 - ETA: 0s - loss: 47.2784 - bcr: 0.6737 - p1: 0.3580 - p2: 0.9894 - m1: 36.2500 - m2: 81.5000 - accuracy: 0.798 - 1s 518ms/step - loss: 46.1574 - bcr: 0.6840 - p1: 0.3821 - p2: 0.9859 - m1: 36.6667 - m2: 80.3333 - accuracy: 0.8007 - val_loss: 86.4576 - val_bcr: 0.4476 - val_p1: 0.2195 - val_p2: 0.6757 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4359\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 23.6711 - bcr: 0.8479 - p1: 0.8276 - p2: 0.8681 - m1: 29.0000 - m2: 91.0000 - accuracy: 0.858 - ETA: 0s - loss: 25.9876 - bcr: 0.8466 - p1: 0.8653 - p2: 0.8280 - m1: 33.2500 - m2: 84.5000 - accuracy: 0.849 - 1s 519ms/step - loss: 26.7597 - bcr: 0.8462 - p1: 0.8778 - p2: 0.8147 - m1: 34.6667 - m2: 82.3333 - accuracy: 0.8460 - val_loss: 81.8724 - val_bcr: 0.5333 - val_p1: 0.6341 - val_p2: 0.4324 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "New best p value : 0.5344088410572088\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 28.8498 - bcr: 0.8525 - p1: 0.9459 - p2: 0.7590 - m1: 37.0000 - m2: 83.0000 - accuracy: 0.816 - ETA: 0s - loss: 26.6185 - bcr: 0.8609 - p1: 0.9266 - p2: 0.7953 - m1: 37.2500 - m2: 80.5000 - accuracy: 0.834 - 1s 522ms/step - loss: 25.8747 - bcr: 0.8637 - p1: 0.9201 - p2: 0.8074 - m1: 37.3333 - m2: 79.6667 - accuracy: 0.8408 - val_loss: 166.2696 - val_bcr: 0.4947 - val_p1: 0.0976 - val_p2: 0.8919 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 36.7120 - bcr: 0.7250 - p1: 0.4500 - p2: 1.0000 - m1: 40.0000 - m2: 80.0000 - accuracy: 0.816 - ETA: 0s - loss: 36.0695 - bcr: 0.7278 - p1: 0.4589 - p2: 0.9967 - m1: 38.7500 - m2: 79.0000 - accuracy: 0.819 - 1s 503ms/step - loss: 35.8554 - bcr: 0.7288 - p1: 0.4619 - p2: 0.9956 - m1: 38.3333 - m2: 78.6667 - accuracy: 0.8206 - val_loss: 96.3685 - val_bcr: 0.5030 - val_p1: 0.1951 - val_p2: 0.8108 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4872\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 22.2073 - bcr: 0.8680 - p1: 0.7941 - p2: 0.9419 - m1: 34.0000 - m2: 86.0000 - accuracy: 0.900 - ETA: 0s - loss: 24.0115 - bcr: 0.8653 - p1: 0.8456 - p2: 0.8850 - m1: 35.7500 - m2: 82.0000 - accuracy: 0.880 - 1s 558ms/step - loss: 24.6129 - bcr: 0.8644 - p1: 0.8627 - p2: 0.8660 - m1: 36.3333 - m2: 80.6667 - accuracy: 0.8743 - val_loss: 78.6634 - val_bcr: 0.5333 - val_p1: 0.6341 - val_p2: 0.4324 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 29.8072 - bcr: 0.8563 - p1: 0.9750 - p2: 0.7375 - m1: 40.0000 - m2: 80.0000 - accuracy: 0.816 - ETA: 0s - loss: 26.8365 - bcr: 0.8675 - p1: 0.9384 - p2: 0.7965 - m1: 38.7500 - m2: 79.0000 - accuracy: 0.843 - 1s 488ms/step - loss: 25.8463 - bcr: 0.8712 - p1: 0.9262 - p2: 0.8162 - m1: 38.3333 - m2: 78.6667 - accuracy: 0.8523 - val_loss: 152.1597 - val_bcr: 0.4947 - val_p1: 0.0976 - val_p2: 0.8919 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 25.2513 - bcr: 0.7273 - p1: 0.4545 - p2: 1.0000 - m1: 33.0000 - m2: 87.0000 - accuracy: 0.850 - ETA: 0s - loss: 26.8179 - bcr: 0.7430 - p1: 0.4897 - p2: 0.9964 - m1: 35.2500 - m2: 82.5000 - accuracy: 0.847 - 1s 508ms/step - loss: 27.3401 - bcr: 0.7483 - p1: 0.5014 - p2: 0.9952 - m1: 36.0000 - m2: 81.0000 - accuracy: 0.8461 - val_loss: 80.0109 - val_bcr: 0.4829 - val_p1: 0.3171 - val_p2: 0.6486 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 15.4739 - bcr: 0.9430 - p1: 0.9231 - p2: 0.9630 - m1: 39.0000 - m2: 81.0000 - accuracy: 0.950 - ETA: 0s - loss: 21.2535 - bcr: 0.9106 - p1: 0.9423 - p2: 0.8789 - m1: 38.2500 - m2: 79.5000 - accuracy: 0.901 - 1s 494ms/step - loss: 23.1800 - bcr: 0.8998 - p1: 0.9487 - p2: 0.8509 - m1: 38.0000 - m2: 79.0000 - accuracy: 0.8852 - val_loss: 72.6961 - val_bcr: 0.4993 - val_p1: 0.5122 - val_p2: 0.4865 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5000\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 19.0704 - bcr: 0.8870 - p1: 0.9512 - p2: 0.8228 - m1: 41.0000 - m2: 79.0000 - accuracy: 0.866 - ETA: 0s - loss: 19.6518 - bcr: 0.8711 - p1: 0.8752 - p2: 0.8671 - m1: 39.2500 - m2: 78.5000 - accuracy: 0.872 - 1s 514ms/step - loss: 19.8456 - bcr: 0.8658 - p1: 0.8498 - p2: 0.8819 - m1: 38.6667 - m2: 78.3333 - accuracy: 0.8747 - val_loss: 145.3836 - val_bcr: 0.4947 - val_p1: 0.0976 - val_p2: 0.8919 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 28.1178 - bcr: 0.7791 - p1: 0.5581 - p2: 1.0000 - m1: 43.0000 - m2: 77.0000 - accuracy: 0.841 - ETA: 0s - loss: 25.1992 - bcr: 0.8109 - p1: 0.6217 - p2: 1.0000 - m1: 40.2500 - m2: 77.5000 - accuracy: 0.866 - 1s 492ms/step - loss: 24.2264 - bcr: 0.8215 - p1: 0.6429 - p2: 1.0000 - m1: 39.3333 - m2: 77.6667 - accuracy: 0.8751 - val_loss: 69.4938 - val_bcr: 0.4980 - val_p1: 0.5366 - val_p2: 0.4595 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 16.2167 - bcr: 0.9101 - p1: 0.9697 - p2: 0.8506 - m1: 33.0000 - m2: 87.0000 - accuracy: 0.883 - ETA: 0s - loss: 18.2651 - bcr: 0.9018 - p1: 0.9773 - p2: 0.8263 - m1: 35.2500 - m2: 82.5000 - accuracy: 0.874 - 1s 541ms/step - loss: 18.9479 - bcr: 0.8990 - p1: 0.9798 - p2: 0.8183 - m1: 36.0000 - m2: 81.0000 - accuracy: 0.8716 - val_loss: 78.2145 - val_bcr: 0.5125 - val_p1: 0.2683 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 14.1054 - bcr: 0.9451 - p1: 0.9286 - p2: 0.9615 - m1: 42.0000 - m2: 78.0000 - accuracy: 0.950 - ETA: 0s - loss: 14.1707 - bcr: 0.9350 - p1: 0.9085 - p2: 0.9615 - m1: 39.7500 - m2: 78.0000 - accuracy: 0.944 - 1s 489ms/step - loss: 14.1925 - bcr: 0.9317 - p1: 0.9019 - p2: 0.9615 - m1: 39.0000 - m2: 78.0000 - accuracy: 0.9429 - val_loss: 108.3799 - val_bcr: 0.4934 - val_p1: 0.1220 - val_p2: 0.8649 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 17.3466 - bcr: 0.8902 - p1: 0.7805 - p2: 1.0000 - m1: 41.0000 - m2: 79.0000 - accuracy: 0.925 - ETA: 0s - loss: 16.7551 - bcr: 0.8977 - p1: 0.7986 - p2: 0.9968 - m1: 39.2500 - m2: 78.5000 - accuracy: 0.930 - 1s 487ms/step - loss: 16.5579 - bcr: 0.9002 - p1: 0.8046 - p2: 0.9957 - m1: 38.6667 - m2: 78.3333 - accuracy: 0.9317 - val_loss: 96.3079 - val_bcr: 0.4934 - val_p1: 0.1220 - val_p2: 0.8649 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 12.3335 - bcr: 0.9545 - p1: 0.9091 - p2: 1.0000 - m1: 33.0000 - m2: 87.0000 - accuracy: 0.975 - ETA: 0s - loss: 12.8911 - bcr: 0.9415 - p1: 0.8902 - p2: 0.9928 - m1: 35.2500 - m2: 82.5000 - accuracy: 0.961 - 1s 474ms/step - loss: 13.0770 - bcr: 0.9371 - p1: 0.8838 - p2: 0.9903 - m1: 36.0000 - m2: 81.0000 - accuracy: 0.9570 - val_loss: 70.5794 - val_bcr: 0.5073 - val_p1: 0.3659 - val_p2: 0.6486 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5000\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 14.0430 - bcr: 0.9503 - p1: 0.9688 - p2: 0.9318 - m1: 32.0000 - m2: 88.0000 - accuracy: 0.941 - ETA: 0s - loss: 14.0196 - bcr: 0.9440 - p1: 0.9649 - p2: 0.9231 - m1: 34.7500 - m2: 83.0000 - accuracy: 0.936 - 1s 502ms/step - loss: 14.0118 - bcr: 0.9419 - p1: 0.9637 - p2: 0.9202 - m1: 35.6667 - m2: 81.3333 - accuracy: 0.9344 - val_loss: 66.2937 - val_bcr: 0.5020 - val_p1: 0.4634 - val_p2: 0.5405 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5000\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 16.7169 - bcr: 0.9167 - p1: 1.0000 - p2: 0.8333 - m1: 42.0000 - m2: 78.0000 - accuracy: 0.891 - ETA: 0s - loss: 15.6491 - bcr: 0.9283 - p1: 0.9848 - p2: 0.8718 - m1: 39.7500 - m2: 78.0000 - accuracy: 0.911 - 1s 480ms/step - loss: 15.2932 - bcr: 0.9322 - p1: 0.9798 - p2: 0.8846 - m1: 39.0000 - m2: 78.0000 - accuracy: 0.9177 - val_loss: 87.3704 - val_bcr: 0.4786 - val_p1: 0.1463 - val_p2: 0.8108 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4615\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 14.2237 - bcr: 0.8886 - p1: 0.7895 - p2: 0.9878 - m1: 38.0000 - m2: 82.0000 - accuracy: 0.925 - ETA: 0s - loss: 13.4917 - bcr: 0.9114 - p1: 0.8353 - p2: 0.9875 - m1: 37.7500 - m2: 80.0000 - accuracy: 0.938 - 1s 554ms/step - loss: 13.2478 - bcr: 0.9190 - p1: 0.8506 - p2: 0.9874 - m1: 37.6667 - m2: 79.3333 - accuracy: 0.9433 - val_loss: 93.4923 - val_bcr: 0.4799 - val_p1: 0.1220 - val_p2: 0.8378 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4615\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 13.3917 - bcr: 0.9375 - p1: 0.8750 - p2: 1.0000 - m1: 40.0000 - m2: 80.0000 - accuracy: 0.958 - ETA: 0s - loss: 13.1069 - bcr: 0.9388 - p1: 0.8777 - p2: 1.0000 - m1: 38.7500 - m2: 79.0000 - accuracy: 0.959 - 1s 550ms/step - loss: 13.0119 - bcr: 0.9393 - p1: 0.8786 - p2: 1.0000 - m1: 38.3333 - m2: 78.6667 - accuracy: 0.9601 - val_loss: 76.9373 - val_bcr: 0.5003 - val_p1: 0.2439 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4872\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.9506 - bcr: 0.9464 - p1: 0.9167 - p2: 0.9762 - m1: 36.0000 - m2: 84.0000 - accuracy: 0.958 - ETA: 0s - loss: 12.0430 - bcr: 0.9497 - p1: 0.9311 - p2: 0.9683 - m1: 36.7500 - m2: 81.0000 - accuracy: 0.957 - 1s 568ms/step - loss: 12.0738 - bcr: 0.9508 - p1: 0.9359 - p2: 0.9656 - m1: 37.0000 - m2: 80.0000 - accuracy: 0.9573 - val_loss: 66.7622 - val_bcr: 0.5181 - val_p1: 0.4146 - val_p2: 0.6216 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5128\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.8536 - bcr: 0.9531 - p1: 0.9412 - p2: 0.9651 - m1: 34.0000 - m2: 86.0000 - accuracy: 0.958 - ETA: 0s - loss: 11.8932 - bcr: 0.9470 - p1: 0.9559 - p2: 0.9381 - m1: 35.7500 - m2: 82.0000 - accuracy: 0.946 - 1s 558ms/step - loss: 12.2397 - bcr: 0.9450 - p1: 0.9608 - p2: 0.9291 - m1: 36.3333 - m2: 80.6667 - accuracy: 0.9428 - val_loss: 71.0678 - val_bcr: 0.5099 - val_p1: 0.3171 - val_p2: 0.7027 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5000\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 12.6533 - bcr: 0.9375 - p1: 0.9500 - p2: 0.9250 - m1: 40.0000 - m2: 80.0000 - accuracy: 0.933 - ETA: 0s - loss: 12.2239 - bcr: 0.9460 - p1: 0.9482 - p2: 0.9437 - m1: 38.7500 - m2: 79.0000 - accuracy: 0.945 - 1s 541ms/step - loss: 12.0808 - bcr: 0.9488 - p1: 0.9476 - p2: 0.9500 - m1: 38.3333 - m2: 78.6667 - accuracy: 0.9489 - val_loss: 100.2560 - val_bcr: 0.4934 - val_p1: 0.1220 - val_p2: 0.8649 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 12.8044 - bcr: 0.8750 - p1: 0.7500 - p2: 1.0000 - m1: 36.0000 - m2: 84.0000 - accuracy: 0.925 - ETA: 0s - loss: 13.1252 - bcr: 0.8838 - p1: 0.7676 - p2: 1.0000 - m1: 36.7500 - m2: 81.0000 - accuracy: 0.927 - 1s 516ms/step - loss: 13.2321 - bcr: 0.8868 - p1: 0.7735 - p2: 1.0000 - m1: 37.0000 - m2: 80.0000 - accuracy: 0.9288 - val_loss: 90.5949 - val_bcr: 0.4799 - val_p1: 0.1220 - val_p2: 0.8378 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4615\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.9328 - bcr: 0.9444 - p1: 0.8889 - p2: 1.0000 - m1: 36.0000 - m2: 84.0000 - accuracy: 0.966 - ETA: 0s - loss: 11.1631 - bcr: 0.9455 - p1: 0.8910 - p2: 1.0000 - m1: 36.7500 - m2: 81.0000 - accuracy: 0.966 - 1s 499ms/step - loss: 11.2398 - bcr: 0.9459 - p1: 0.8917 - p2: 1.0000 - m1: 37.0000 - m2: 80.0000 - accuracy: 0.9658 - val_loss: 70.7557 - val_bcr: 0.5234 - val_p1: 0.3171 - val_p2: 0.7297 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5128\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.5495 - bcr: 0.9744 - p1: 0.9730 - p2: 0.9759 - m1: 37.0000 - m2: 83.0000 - accuracy: 0.975 - ETA: 0s - loss: 10.9598 - bcr: 0.9673 - p1: 0.9732 - p2: 0.9614 - m1: 37.2500 - m2: 80.5000 - accuracy: 0.965 - 1s 486ms/step - loss: 11.0966 - bcr: 0.9649 - p1: 0.9732 - p2: 0.9565 - m1: 37.3333 - m2: 79.6667 - accuracy: 0.9628 - val_loss: 63.9346 - val_bcr: 0.4911 - val_p1: 0.4146 - val_p2: 0.5676 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4872\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.7401 - bcr: 0.9753 - p1: 1.0000 - p2: 0.9506 - m1: 39.0000 - m2: 81.0000 - accuracy: 0.966 - ETA: 0s - loss: 11.6444 - bcr: 0.9598 - p1: 1.0000 - p2: 0.9196 - m1: 38.2500 - m2: 79.5000 - accuracy: 0.946 - 1s 596ms/step - loss: 11.9458 - bcr: 0.9547 - p1: 1.0000 - p2: 0.9093 - m1: 38.0000 - m2: 79.0000 - accuracy: 0.9398 - val_loss: 66.7207 - val_bcr: 0.4951 - val_p1: 0.3415 - val_p2: 0.6486 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4872\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.0410 - bcr: 0.9695 - p1: 1.0000 - p2: 0.9390 - m1: 38.0000 - m2: 82.0000 - accuracy: 0.958 - ETA: 0s - loss: 11.0587 - bcr: 0.9687 - p1: 0.9865 - p2: 0.9509 - m1: 37.7500 - m2: 80.0000 - accuracy: 0.961 - 1s 516ms/step - loss: 11.0646 - bcr: 0.9684 - p1: 0.9820 - p2: 0.9548 - m1: 37.6667 - m2: 79.3333 - accuracy: 0.9630 - val_loss: 84.6219 - val_bcr: 0.4908 - val_p1: 0.1707 - val_p2: 0.8108 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.9492 - bcr: 0.9359 - p1: 0.8718 - p2: 1.0000 - m1: 39.0000 - m2: 81.0000 - accuracy: 0.958 - ETA: 0s - loss: 11.6482 - bcr: 0.9311 - p1: 0.8622 - p2: 1.0000 - m1: 38.2500 - m2: 79.5000 - accuracy: 0.955 - 1s 523ms/step - loss: 11.5479 - bcr: 0.9295 - p1: 0.8590 - p2: 1.0000 - m1: 38.0000 - m2: 79.0000 - accuracy: 0.9544 - val_loss: 89.8917 - val_bcr: 0.4799 - val_p1: 0.1220 - val_p2: 0.8378 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4615\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 12.3309 - bcr: 0.9111 - p1: 0.8222 - p2: 1.0000 - m1: 45.0000 - m2: 75.0000 - accuracy: 0.933 - ETA: 0s - loss: 11.8915 - bcr: 0.9292 - p1: 0.8583 - p2: 1.0000 - m1: 41.2500 - m2: 76.5000 - accuracy: 0.947 - 1s 506ms/step - loss: 11.7450 - bcr: 0.9352 - p1: 0.8704 - p2: 1.0000 - m1: 40.0000 - m2: 77.0000 - accuracy: 0.9518 - val_loss: 76.0128 - val_bcr: 0.4881 - val_p1: 0.2195 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4217 - bcr: 0.9698 - p1: 0.9524 - p2: 0.9872 - m1: 42.0000 - m2: 78.0000 - accuracy: 0.975 - ETA: 0s - loss: 10.4346 - bcr: 0.9719 - p1: 0.9567 - p2: 0.9872 - m1: 39.7500 - m2: 78.0000 - accuracy: 0.976 - 1s 498ms/step - loss: 10.4389 - bcr: 0.9727 - p1: 0.9582 - p2: 0.9872 - m1: 39.0000 - m2: 78.0000 - accuracy: 0.9772 - val_loss: 66.5570 - val_bcr: 0.4951 - val_p1: 0.3415 - val_p2: 0.6486 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4872\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4132 - bcr: 0.9504 - p1: 0.9706 - p2: 0.9302 - m1: 34.0000 - m2: 86.0000 - accuracy: 0.941 - ETA: 0s - loss: 10.5616 - bcr: 0.9575 - p1: 0.9779 - p2: 0.9370 - m1: 35.7500 - m2: 82.0000 - accuracy: 0.949 - 1s 532ms/step - loss: 10.6111 - bcr: 0.9598 - p1: 0.9804 - p2: 0.9392 - m1: 36.3333 - m2: 80.6667 - accuracy: 0.9517 - val_loss: 65.9490 - val_bcr: 0.4951 - val_p1: 0.3415 - val_p2: 0.6486 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4872\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.6048 - bcr: 0.9688 - p1: 1.0000 - p2: 0.9375 - m1: 40.0000 - m2: 80.0000 - accuracy: 0.958 - ETA: 0s - loss: 10.5747 - bcr: 0.9661 - p1: 0.9857 - p2: 0.9465 - m1: 38.7500 - m2: 79.0000 - accuracy: 0.959 - 1s 493ms/step - loss: 10.5647 - bcr: 0.9653 - p1: 0.9810 - p2: 0.9496 - m1: 38.3333 - m2: 78.6667 - accuracy: 0.9601 - val_loss: 71.4780 - val_bcr: 0.5369 - val_p1: 0.3171 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5256\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "New best p value : 0.5370085434404496\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3636 - bcr: 0.9746 - p1: 0.9737 - p2: 0.9756 - m1: 38.0000 - m2: 82.0000 - accuracy: 0.975 - ETA: 0s - loss: 10.3073 - bcr: 0.9776 - p1: 0.9735 - p2: 0.9817 - m1: 37.7500 - m2: 80.0000 - accuracy: 0.978 - 1s 464ms/step - loss: 10.2886 - bcr: 0.9786 - p1: 0.9734 - p2: 0.9837 - m1: 37.6667 - m2: 79.3333 - accuracy: 0.9801 - val_loss: 74.4683 - val_bcr: 0.5003 - val_p1: 0.2439 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4872\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.8318 - bcr: 0.9815 - p1: 0.9756 - p2: 0.9873 - m1: 41.0000 - m2: 79.0000 - accuracy: 0.98 - ETA: 0s - loss: 10.0075 - bcr: 0.9771 - p1: 0.9670 - p2: 0.9873 - m1: 39.2500 - m2: 78.5000 - accuracy: 0.980 - 1s 510ms/step - loss: 10.0661 - bcr: 0.9757 - p1: 0.9641 - p2: 0.9872 - m1: 38.6667 - m2: 78.3333 - accuracy: 0.9800 - val_loss: 76.4116 - val_bcr: 0.4637 - val_p1: 0.1707 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4487\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.3227 - bcr: 0.9375 - p1: 0.9000 - p2: 0.9750 - m1: 40.0000 - m2: 80.0000 - accuracy: 0.950 - ETA: 0s - loss: 10.2465 - bcr: 0.9496 - p1: 0.9179 - p2: 0.9813 - m1: 38.7500 - m2: 79.0000 - accuracy: 0.959 - 1s 487ms/step - loss: 10.2211 - bcr: 0.9536 - p1: 0.9238 - p2: 0.9833 - m1: 38.3333 - m2: 78.6667 - accuracy: 0.9631 - val_loss: 75.9040 - val_bcr: 0.4759 - val_p1: 0.1951 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4615\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.2434 - bcr: 0.9641 - p1: 0.9545 - p2: 0.9737 - m1: 44.0000 - m2: 76.0000 - accuracy: 0.966 - ETA: 0s - loss: 10.1739 - bcr: 0.9691 - p1: 0.9578 - p2: 0.9803 - m1: 40.7500 - m2: 77.0000 - accuracy: 0.972 - 1s 486ms/step - loss: 10.1507 - bcr: 0.9707 - p1: 0.9589 - p2: 0.9825 - m1: 39.6667 - m2: 77.3333 - accuracy: 0.9745 - val_loss: 74.2491 - val_bcr: 0.5003 - val_p1: 0.2439 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4872\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.4290 - bcr: 0.9533 - p1: 0.9333 - p2: 0.9733 - m1: 45.0000 - m2: 75.0000 - accuracy: 0.958 - ETA: 0s - loss: 10.2296 - bcr: 0.9650 - p1: 0.9500 - p2: 0.9800 - m1: 41.2500 - m2: 76.5000 - accuracy: 0.968 - 1s 476ms/step - loss: 10.1631 - bcr: 0.9689 - p1: 0.9556 - p2: 0.9822 - m1: 40.0000 - m2: 77.0000 - accuracy: 0.9717 - val_loss: 71.8054 - val_bcr: 0.5369 - val_p1: 0.3171 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5256\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.9051 - bcr: 0.9802 - p1: 0.9722 - p2: 0.9881 - m1: 36.0000 - m2: 84.0000 - accuracy: 0.98 - ETA: 0s - loss: 9.9283 - bcr: 0.9802 - p1: 0.9728 - p2: 0.9876 - m1: 36.7500 - m2: 81.0000 - accuracy: 0.98 - 1s 528ms/step - loss: 9.9360 - bcr: 0.9802 - p1: 0.9729 - p2: 0.9874 - m1: 37.0000 - m2: 80.0000 - accuracy: 0.9829 - val_loss: 69.9870 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "New best p value : 0.5492041682819444\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.8253 - bcr: 0.9798 - p1: 0.9714 - p2: 0.9882 - m1: 35.0000 - m2: 85.0000 - accuracy: 0.98 - ETA: 0s - loss: 9.8673 - bcr: 0.9800 - p1: 0.9723 - p2: 0.9877 - m1: 36.2500 - m2: 81.5000 - accuracy: 0.98 - 1s 502ms/step - loss: 9.8813 - bcr: 0.9800 - p1: 0.9726 - p2: 0.9875 - m1: 36.6667 - m2: 80.3333 - accuracy: 0.9829 - val_loss: 68.6372 - val_bcr: 0.5221 - val_p1: 0.3415 - val_p2: 0.7027 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5128\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.7603 - bcr: 0.9611 - p1: 0.9333 - p2: 0.9889 - m1: 30.0000 - m2: 90.0000 - accuracy: 0.97 - ETA: 0s - loss: 9.8347 - bcr: 0.9670 - p1: 0.9500 - p2: 0.9841 - m1: 33.7500 - m2: 84.0000 - accuracy: 0.97 - 1s 513ms/step - loss: 9.8595 - bcr: 0.9690 - p1: 0.9556 - p2: 0.9825 - m1: 35.0000 - m2: 82.0000 - accuracy: 0.9772 - val_loss: 67.6546 - val_bcr: 0.5221 - val_p1: 0.3415 - val_p2: 0.7027 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5128\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.7476 - bcr: 0.9937 - p1: 1.0000 - p2: 0.9875 - m1: 40.0000 - m2: 80.0000 - accuracy: 0.99 - ETA: 0s - loss: 9.7984 - bcr: 0.9885 - p1: 0.9929 - p2: 0.9840 - m1: 38.7500 - m2: 79.0000 - accuracy: 0.98 - 1s 521ms/step - loss: 9.8153 - bcr: 0.9867 - p1: 0.9905 - p2: 0.9829 - m1: 38.3333 - m2: 78.6667 - accuracy: 0.9857 - val_loss: 68.2210 - val_bcr: 0.5221 - val_p1: 0.3415 - val_p2: 0.7027 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5128\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 10.0402 - bcr: 0.9734 - p1: 0.9697 - p2: 0.9770 - m1: 33.0000 - m2: 87.0000 - accuracy: 0.975 - ETA: 0s - loss: 9.9155 - bcr: 0.9752 - p1: 0.9713 - p2: 0.9791 - m1: 35.2500 - m2: 82.5000 - accuracy: 0.976 - 1s 611ms/step - loss: 9.8740 - bcr: 0.9759 - p1: 0.9719 - p2: 0.9798 - m1: 36.0000 - m2: 81.0000 - accuracy: 0.9772 - val_loss: 69.3921 - val_bcr: 0.5356 - val_p1: 0.3415 - val_p2: 0.7297 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5256\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.5181 - bcr: 0.9861 - p1: 0.9722 - p2: 1.0000 - m1: 36.0000 - m2: 84.0000 - accuracy: 0.99 - ETA: 0s - loss: 9.6218 - bcr: 0.9829 - p1: 0.9728 - p2: 0.9931 - m1: 36.7500 - m2: 81.0000 - accuracy: 0.98 - 1s 639ms/step - loss: 9.6564 - bcr: 0.9818 - p1: 0.9729 - p2: 0.9907 - m1: 37.0000 - m2: 80.0000 - accuracy: 0.9857 - val_loss: 69.7319 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "New best p value : 0.5492049757838374\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.6013 - bcr: 0.9822 - p1: 0.9778 - p2: 0.9867 - m1: 45.0000 - m2: 75.0000 - accuracy: 0.98 - ETA: 0s - loss: 9.6434 - bcr: 0.9810 - p1: 0.9750 - p2: 0.9869 - m1: 41.2500 - m2: 76.5000 - accuracy: 0.98 - 1s 598ms/step - loss: 9.6574 - bcr: 0.9805 - p1: 0.9741 - p2: 0.9870 - m1: 40.0000 - m2: 77.0000 - accuracy: 0.9829 - val_loss: 70.1668 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "New best p value : 0.549204991278037\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.8201 - bcr: 0.9755 - p1: 0.9773 - p2: 0.9737 - m1: 44.0000 - m2: 76.0000 - accuracy: 0.97 - ETA: 0s - loss: 9.7429 - bcr: 0.9776 - p1: 0.9749 - p2: 0.9803 - m1: 40.7500 - m2: 77.0000 - accuracy: 0.97 - 1s 533ms/step - loss: 9.7172 - bcr: 0.9783 - p1: 0.9741 - p2: 0.9825 - m1: 39.6667 - m2: 77.3333 - accuracy: 0.9801 - val_loss: 70.6631 - val_bcr: 0.5369 - val_p1: 0.3171 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5256\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.6151 - bcr: 0.9868 - p1: 0.9737 - p2: 1.0000 - m1: 38.0000 - m2: 82.0000 - accuracy: 0.99 - ETA: 0s - loss: 9.6258 - bcr: 0.9834 - p1: 0.9735 - p2: 0.9932 - m1: 37.7500 - m2: 80.0000 - accuracy: 0.98 - 1s 504ms/step - loss: 9.6293 - bcr: 0.9822 - p1: 0.9734 - p2: 0.9910 - m1: 37.6667 - m2: 79.3333 - accuracy: 0.9857 - val_loss: 70.7537 - val_bcr: 0.5369 - val_p1: 0.3171 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5256\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.5719 - bcr: 0.9810 - p1: 0.9744 - p2: 0.9877 - m1: 39.0000 - m2: 81.0000 - accuracy: 0.98 - ETA: 0s - loss: 9.5905 - bcr: 0.9806 - p1: 0.9738 - p2: 0.9874 - m1: 38.2500 - m2: 79.5000 - accuracy: 0.98 - 1s 475ms/step - loss: 9.5967 - bcr: 0.9805 - p1: 0.9736 - p2: 0.9873 - m1: 38.0000 - m2: 79.0000 - accuracy: 0.9829 - val_loss: 70.9710 - val_bcr: 0.5369 - val_p1: 0.3171 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5256\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.6961 - bcr: 0.9730 - p1: 0.9688 - p2: 0.9773 - m1: 32.0000 - m2: 88.0000 - accuracy: 0.97 - ETA: 0s - loss: 9.6417 - bcr: 0.9769 - p1: 0.9707 - p2: 0.9830 - m1: 34.7500 - m2: 83.0000 - accuracy: 0.97 - 1s 501ms/step - loss: 9.6236 - bcr: 0.9781 - p1: 0.9714 - p2: 0.9848 - m1: 35.6667 - m2: 81.3333 - accuracy: 0.9801 - val_loss: 71.2719 - val_bcr: 0.5247 - val_p1: 0.2927 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5128\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.4554 - bcr: 0.9857 - p1: 0.9714 - p2: 1.0000 - m1: 35.0000 - m2: 85.0000 - accuracy: 0.99 - ETA: 0s - loss: 9.5064 - bcr: 0.9826 - p1: 0.9723 - p2: 0.9930 - m1: 36.2500 - m2: 81.5000 - accuracy: 0.98 - 1s 475ms/step - loss: 9.5234 - bcr: 0.9816 - p1: 0.9726 - p2: 0.9906 - m1: 36.6667 - m2: 80.3333 - accuracy: 0.9857 - val_loss: 71.1610 - val_bcr: 0.5247 - val_p1: 0.2927 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5128\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.4363 - bcr: 0.9882 - p1: 1.0000 - p2: 0.9765 - m1: 35.0000 - m2: 85.0000 - accuracy: 0.98 - ETA: 0s - loss: 9.4912 - bcr: 0.9849 - p1: 0.9875 - p2: 0.9824 - m1: 36.2500 - m2: 81.5000 - accuracy: 0.98 - 1s 518ms/step - loss: 9.5095 - bcr: 0.9838 - p1: 0.9833 - p2: 0.9843 - m1: 36.6667 - m2: 80.3333 - accuracy: 0.9829 - val_loss: 71.4070 - val_bcr: 0.5247 - val_p1: 0.2927 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5128\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.4253 - bcr: 0.9878 - p1: 0.9756 - p2: 1.0000 - m1: 41.0000 - m2: 79.0000 - accuracy: 0.99 - ETA: 0s - loss: 9.4681 - bcr: 0.9856 - p1: 0.9744 - p2: 0.9968 - m1: 39.2500 - m2: 78.5000 - accuracy: 0.98 - 1s 532ms/step - loss: 9.4824 - bcr: 0.9848 - p1: 0.9739 - p2: 0.9957 - m1: 38.6667 - m2: 78.3333 - accuracy: 0.9886 - val_loss: 70.9918 - val_bcr: 0.5247 - val_p1: 0.2927 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5128\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.3991 - bcr: 0.9798 - p1: 0.9714 - p2: 0.9882 - m1: 35.0000 - m2: 85.0000 - accuracy: 0.98 - ETA: 0s - loss: 9.4411 - bcr: 0.9800 - p1: 0.9723 - p2: 0.9877 - m1: 36.2500 - m2: 81.5000 - accuracy: 0.98 - 1s 496ms/step - loss: 9.4551 - bcr: 0.9800 - p1: 0.9726 - p2: 0.9875 - m1: 36.6667 - m2: 80.3333 - accuracy: 0.9829 - val_loss: 70.5688 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.3620 - bcr: 0.9881 - p1: 0.9762 - p2: 1.0000 - m1: 42.0000 - m2: 78.0000 - accuracy: 0.99 - ETA: 0s - loss: 9.4114 - bcr: 0.9841 - p1: 0.9746 - p2: 0.9936 - m1: 39.7500 - m2: 78.0000 - accuracy: 0.98 - 1s 482ms/step - loss: 9.4279 - bcr: 0.9827 - p1: 0.9740 - p2: 0.9915 - m1: 39.0000 - m2: 78.0000 - accuracy: 0.9857 - val_loss: 70.3026 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.3772 - bcr: 0.9939 - p1: 1.0000 - p2: 0.9878 - m1: 38.0000 - m2: 82.0000 - accuracy: 0.99 - ETA: 0s - loss: 9.4065 - bcr: 0.9870 - p1: 0.9865 - p2: 0.9875 - m1: 37.7500 - m2: 80.0000 - accuracy: 0.98 - 1s 511ms/step - loss: 9.4163 - bcr: 0.9847 - p1: 0.9820 - p2: 0.9874 - m1: 37.6667 - m2: 79.3333 - accuracy: 0.9857 - val_loss: 70.2122 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.4580 - bcr: 0.9767 - p1: 0.9535 - p2: 1.0000 - m1: 43.0000 - m2: 77.0000 - accuracy: 0.98 - ETA: 0s - loss: 9.4443 - bcr: 0.9794 - p1: 0.9651 - p2: 0.9937 - m1: 40.2500 - m2: 77.5000 - accuracy: 0.98 - 1s 508ms/step - loss: 9.4398 - bcr: 0.9803 - p1: 0.9690 - p2: 0.9916 - m1: 39.3333 - m2: 77.6667 - accuracy: 0.9829 - val_loss: 69.9279 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.4314 - bcr: 0.9778 - p1: 0.9556 - p2: 1.0000 - m1: 45.0000 - m2: 75.0000 - accuracy: 0.98 - ETA: 0s - loss: 9.4252 - bcr: 0.9802 - p1: 0.9667 - p2: 0.9938 - m1: 41.2500 - m2: 76.5000 - accuracy: 0.98 - 1s 491ms/step - loss: 9.4232 - bcr: 0.9811 - p1: 0.9704 - p2: 0.9918 - m1: 40.0000 - m2: 77.0000 - accuracy: 0.9829 - val_loss: 69.7777 - val_bcr: 0.5356 - val_p1: 0.3415 - val_p2: 0.7297 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5256\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.2923 - bcr: 1.0000 - p1: 1.0000 - p2: 1.0000 - m1: 40.0000 - m2: 80.0000 - accuracy: 1.00 - ETA: 0s - loss: 9.3456 - bcr: 0.9931 - p1: 0.9929 - p2: 0.9934 - m1: 38.7500 - m2: 79.0000 - accuracy: 0.99 - 1s 473ms/step - loss: 9.3633 - bcr: 0.9909 - p1: 0.9905 - p2: 0.9912 - m1: 38.3333 - m2: 78.6667 - accuracy: 0.9913 - val_loss: 69.8630 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.4168 - bcr: 0.9813 - p1: 0.9750 - p2: 0.9875 - m1: 40.0000 - m2: 80.0000 - accuracy: 0.98 - ETA: 0s - loss: 9.4012 - bcr: 0.9843 - p1: 0.9813 - p2: 0.9873 - m1: 38.7500 - m2: 79.0000 - accuracy: 0.98 - 1s 510ms/step - loss: 9.3960 - bcr: 0.9853 - p1: 0.9833 - p2: 0.9873 - m1: 38.3333 - m2: 78.6667 - accuracy: 0.9858 - val_loss: 70.0218 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.4678 - bcr: 0.9748 - p1: 0.9744 - p2: 0.9753 - m1: 39.0000 - m2: 81.0000 - accuracy: 0.97 - ETA: 0s - loss: 9.4215 - bcr: 0.9811 - p1: 0.9808 - p2: 0.9815 - m1: 38.2500 - m2: 79.5000 - accuracy: 0.98 - 1s 497ms/step - loss: 9.4061 - bcr: 0.9832 - p1: 0.9829 - p2: 0.9835 - m1: 38.0000 - m2: 79.0000 - accuracy: 0.9830 - val_loss: 70.2372 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.2799 - bcr: 0.9861 - p1: 0.9722 - p2: 1.0000 - m1: 36.0000 - m2: 84.0000 - accuracy: 0.99 - ETA: 0s - loss: 9.3208 - bcr: 0.9846 - p1: 0.9728 - p2: 0.9965 - m1: 36.7500 - m2: 81.0000 - accuracy: 0.98 - 1s 498ms/step - loss: 9.3344 - bcr: 0.9842 - p1: 0.9729 - p2: 0.9954 - m1: 37.0000 - m2: 80.0000 - accuracy: 0.9886 - val_loss: 70.3324 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.3914 - bcr: 0.9857 - p1: 0.9714 - p2: 1.0000 - m1: 35.0000 - m2: 85.0000 - accuracy: 0.99 - ETA: 0s - loss: 9.3718 - bcr: 0.9844 - p1: 0.9723 - p2: 0.9965 - m1: 36.2500 - m2: 81.5000 - accuracy: 0.98 - 1s 518ms/step - loss: 9.3652 - bcr: 0.9840 - p1: 0.9726 - p2: 0.9953 - m1: 36.6667 - m2: 80.3333 - accuracy: 0.9886 - val_loss: 70.3290 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.3893 - bcr: 0.9737 - p1: 0.9474 - p2: 1.0000 - m1: 38.0000 - m2: 82.0000 - accuracy: 0.98 - ETA: 0s - loss: 9.3667 - bcr: 0.9786 - p1: 0.9605 - p2: 0.9966 - m1: 37.7500 - m2: 80.0000 - accuracy: 0.98 - 1s 506ms/step - loss: 9.3592 - bcr: 0.9802 - p1: 0.9649 - p2: 0.9955 - m1: 37.6667 - m2: 79.3333 - accuracy: 0.9858 - val_loss: 70.2021 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.3707 - bcr: 0.9881 - p1: 0.9762 - p2: 1.0000 - m1: 42.0000 - m2: 78.0000 - accuracy: 0.99 - ETA: 0s - loss: 9.3518 - bcr: 0.9895 - p1: 0.9821 - p2: 0.9968 - m1: 39.7500 - m2: 78.0000 - accuracy: 0.99 - 1s 519ms/step - loss: 9.3455 - bcr: 0.9899 - p1: 0.9841 - p2: 0.9957 - m1: 39.0000 - m2: 78.0000 - accuracy: 0.9915 - val_loss: 70.1258 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.3544 - bcr: 0.9865 - p1: 0.9730 - p2: 1.0000 - m1: 37.0000 - m2: 83.0000 - accuracy: 0.99 - ETA: 0s - loss: 9.3382 - bcr: 0.9882 - p1: 0.9797 - p2: 0.9966 - m1: 37.2500 - m2: 80.5000 - accuracy: 0.99 - 1s 518ms/step - loss: 9.3328 - bcr: 0.9887 - p1: 0.9820 - p2: 0.9954 - m1: 37.3333 - m2: 79.6667 - accuracy: 0.9915 - val_loss: 70.0774 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.3834 - bcr: 0.9815 - p1: 0.9756 - p2: 0.9873 - m1: 41.0000 - m2: 79.0000 - accuracy: 0.98 - ETA: 0s - loss: 9.3495 - bcr: 0.9861 - p1: 0.9817 - p2: 0.9905 - m1: 39.2500 - m2: 78.5000 - accuracy: 0.98 - 1s 517ms/step - loss: 9.3382 - bcr: 0.9877 - p1: 0.9837 - p2: 0.9916 - m1: 38.6667 - m2: 78.3333 - accuracy: 0.9887 - val_loss: 70.0857 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.2432 - bcr: 1.0000 - p1: 1.0000 - p2: 1.0000 - m1: 38.0000 - m2: 82.0000 - accuracy: 1.00 - ETA: 0s - loss: 9.2770 - bcr: 0.9949 - p1: 0.9932 - p2: 0.9966 - m1: 37.7500 - m2: 80.0000 - accuracy: 0.99 - 1s 512ms/step - loss: 9.2883 - bcr: 0.9932 - p1: 0.9910 - p2: 0.9955 - m1: 37.6667 - m2: 79.3333 - accuracy: 0.9942 - val_loss: 70.0736 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.2390 - bcr: 1.0000 - p1: 1.0000 - p2: 1.0000 - m1: 38.0000 - m2: 82.0000 - accuracy: 1.00 - ETA: 0s - loss: 9.2719 - bcr: 0.9949 - p1: 0.9932 - p2: 0.9966 - m1: 37.7500 - m2: 80.0000 - accuracy: 0.99 - 1s 516ms/step - loss: 9.2828 - bcr: 0.9932 - p1: 0.9910 - p2: 0.9955 - m1: 37.6667 - m2: 79.3333 - accuracy: 0.9942 - val_loss: 70.0560 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - ETA: 1s - loss: 9.2651 - bcr: 0.9943 - p1: 1.0000 - p2: 0.9886 - m1: 32.0000 - m2: 88.0000 - accuracy: 0.99 - ETA: 0s - loss: 9.2825 - bcr: 0.9928 - p1: 0.9942 - p2: 0.9915 - m1: 34.7500 - m2: 83.0000 - accuracy: 0.99 - 2s 1s/step - loss: 9.2883 - bcr: 0.9923 - p1: 0.9922 - p2: 0.9924 - m1: 35.6667 - m2: 81.3333 - accuracy: 0.9915 - val_loss: 70.0742 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.2579 - bcr: 0.9937 - p1: 1.0000 - p2: 0.9875 - m1: 40.0000 - m2: 80.0000 - accuracy: 0.99 - ETA: 0s - loss: 9.2766 - bcr: 0.9917 - p1: 0.9929 - p2: 0.9906 - m1: 38.7500 - m2: 79.0000 - accuracy: 0.99 - 1s 537ms/step - loss: 9.2829 - bcr: 0.9911 - p1: 0.9905 - p2: 0.9917 - m1: 38.3333 - m2: 78.6667 - accuracy: 0.9915 - val_loss: 70.0799 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.2260 - bcr: 1.0000 - p1: 1.0000 - p2: 1.0000 - m1: 42.0000 - m2: 78.0000 - accuracy: 1.00 - ETA: 0s - loss: 9.2575 - bcr: 0.9946 - p1: 0.9924 - p2: 0.9968 - m1: 39.7500 - m2: 78.0000 - accuracy: 0.99 - 1s 540ms/step - loss: 9.2680 - bcr: 0.9928 - p1: 0.9899 - p2: 0.9957 - m1: 39.0000 - m2: 78.0000 - accuracy: 0.9942 - val_loss: 70.0301 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.2493 - bcr: 0.9936 - p1: 1.0000 - p2: 0.9872 - m1: 42.0000 - m2: 78.0000 - accuracy: 0.99 - ETA: 0s - loss: 9.2667 - bcr: 0.9914 - p1: 0.9924 - p2: 0.9904 - m1: 39.7500 - m2: 78.0000 - accuracy: 0.99 - 1s 489ms/step - loss: 9.2724 - bcr: 0.9907 - p1: 0.9899 - p2: 0.9915 - m1: 39.0000 - m2: 78.0000 - accuracy: 0.9915 - val_loss: 70.0064 - val_bcr: 0.5491 - val_p1: 0.3415 - val_p2: 0.7568 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.3091 - bcr: 0.9875 - p1: 0.9750 - p2: 1.0000 - m1: 40.0000 - m2: 80.0000 - accuracy: 0.99 - ETA: 0s - loss: 9.2948 - bcr: 0.9890 - p1: 0.9813 - p2: 0.9967 - m1: 38.7500 - m2: 79.0000 - accuracy: 0.99 - 1s 528ms/step - loss: 9.2900 - bcr: 0.9895 - p1: 0.9833 - p2: 0.9956 - m1: 38.3333 - m2: 78.6667 - accuracy: 0.9915 - val_loss: 69.9151 - val_bcr: 0.5356 - val_p1: 0.3415 - val_p2: 0.7297 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5256\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.2443 - bcr: 0.9937 - p1: 1.0000 - p2: 0.9873 - m1: 41.0000 - m2: 79.0000 - accuracy: 0.99 - ETA: 0s - loss: 9.2594 - bcr: 0.9916 - p1: 0.9926 - p2: 0.9905 - m1: 39.2500 - m2: 78.5000 - accuracy: 0.99 - 1s 656ms/step - loss: 9.2645 - bcr: 0.9909 - p1: 0.9902 - p2: 0.9916 - m1: 38.6667 - m2: 78.3333 - accuracy: 0.9915 - val_loss: 69.9226 - val_bcr: 0.5356 - val_p1: 0.3415 - val_p2: 0.7297 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5256\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 9.2982 - bcr: 0.9878 - p1: 0.9756 - p2: 1.0000 - m1: 41.0000 - m2: 79.0000 - accuracy: 0.99 - ETA: 0s - loss: 9.2840 - bcr: 0.9892 - p1: 0.9817 - p2: 0.9968 - m1: 39.2500 - m2: 78.5000 - accuracy: 0.99 - 1s 636ms/step - loss: 9.2792 - bcr: 0.9897 - p1: 0.9837 - p2: 0.9957 - m1: 38.6667 - m2: 78.3333 - accuracy: 0.9915 - val_loss: 69.8917 - val_bcr: 0.5356 - val_p1: 0.3415 - val_p2: 0.7297 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5256\n",
      "Restoring model weights from the end of the best epoch. Best value : 0.549\n",
      "Epoch 00105: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    batch_size=120,\n",
    "                    epochs=200,\n",
    "                    callbacks=callbacks\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e403428f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Report for Functional -------------------\n",
      "\n",
      "P score : 0.573\n",
      "BCR     : 0.673\n",
      "BCR hat : 0.569\n"
     ]
    }
   ],
   "source": [
    "report = Report(model, X_train, y_train, X_val, y_val).to_stdout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapidsai",
   "language": "python",
   "name": "rapidsai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
