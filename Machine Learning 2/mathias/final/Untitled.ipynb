{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"ML-A5-2022_train.csv\", index_col=0)\n",
    "test_df = pd.read_csv(\"ML-A5-2022_test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 2., 0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf = test_df.copy()\n",
    "testdf = testdf.replace({\"low\": 0, \"medium\":1, \"high\": 2})\n",
    "testdf.fillna(testdf.median(), inplace=True)\n",
    "testtab=testdf.to_numpy()\n",
    "testtab[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C-1001', 'C-1002', 'C-1003', 'C-1004', 'C-1005', 'C-1006',\n",
       "       'C-1007', 'C-1008', 'C-1009', 'C-1010', 'C-1011', 'C-1012',\n",
       "       'C-1013', 'C-1014', 'C-1015', 'C-1016', 'C-1017', 'C-1018',\n",
       "       'C-1019', 'C-1020', 'C-1021', 'C-1022', 'C-1023', 'C-1024',\n",
       "       'C-1025', 'C-1026', 'C-1027', 'C-1028', 'C-1029', 'C-1030',\n",
       "       'C-1031', 'C-1032', 'C-1033', 'C-1034', 'C-1035', 'C-1036',\n",
       "       'C-1037', 'C-1038', 'C-1039', 'C-1040', 'C-1041', 'C-1042',\n",
       "       'C-1043', 'C-1044', 'C-1045', 'C-1046', 'C-1047', 'C-1048',\n",
       "       'C-1049', 'C-1050', 'C-1051', 'C-1052', 'C-1053', 'C-1054',\n",
       "       'C-1055', 'C-1056', 'C-1057', 'C-1058', 'C-1059', 'C-1060',\n",
       "       'C-1061', 'C-1062', 'C-1063', 'C-1064', 'C-1065', 'C-1066',\n",
       "       'C-1067', 'C-1068', 'C-1069', 'C-1070', 'C-1071', 'C-1072',\n",
       "       'C-1073', 'C-1074', 'C-1075', 'C-1076', 'C-1077', 'C-1078',\n",
       "       'C-1079', 'C-1080', 'C-1081', 'C-1082', 'C-1083', 'C-1084',\n",
       "       'C-1085', 'C-1086', 'C-1087', 'C-1088', 'C-1089', 'C-1090',\n",
       "       'C-1091', 'C-1092', 'C-1093', 'C-1094', 'C-1095', 'C-1096',\n",
       "       'C-1097', 'C-1098', 'C-1099', 'C-1100', 'C-1101', 'C-1102',\n",
       "       'C-1103', 'C-1104', 'C-1105', 'C-1106', 'C-1107', 'C-1108',\n",
       "       'C-1109', 'C-1110', 'C-1111', 'C-1112', 'C-1113', 'C-1114',\n",
       "       'C-1115', 'C-1116', 'C-1117', 'C-1118', 'C-1119', 'C-1120',\n",
       "       'C-1121', 'C-1122', 'C-1123', 'C-1124', 'C-1125', 'C-1126',\n",
       "       'C-1127', 'C-1128', 'C-1129', 'C-1130', 'C-1131', 'C-1132',\n",
       "       'C-1133', 'C-1134', 'C-1135', 'C-1136', 'C-1137', 'C-1138',\n",
       "       'C-1139', 'C-1140', 'C-1141', 'C-1142', 'C-1143', 'C-1144',\n",
       "       'C-1145', 'C-1146', 'C-1147', 'C-1148', 'C-1149', 'C-1150',\n",
       "       'C-1151', 'C-1152', 'C-1153', 'C-1154', 'C-1155', 'C-1156',\n",
       "       'C-1157', 'C-1158', 'C-1159', 'C-1160', 'C-1161', 'C-1162',\n",
       "       'C-1163', 'C-1164', 'C-1165', 'C-1166', 'C-1167', 'C-1168',\n",
       "       'C-1169', 'C-1170', 'C-1171', 'C-1172', 'C-1173', 'C-1174',\n",
       "       'C-1175', 'C-1176', 'C-1177', 'C-1178', 'C-1179', 'C-1180',\n",
       "       'C-1181', 'C-1182', 'C-1183', 'C-1184', 'C-1185', 'C-1186',\n",
       "       'C-1187', 'C-1188', 'C-1189', 'C-1190', 'C-1191', 'C-1192',\n",
       "       'C-1193', 'C-1194', 'C-1195', 'C-1196', 'C-1197', 'C-1198',\n",
       "       'C-1199', 'C-1200', 'C-1201', 'C-1202', 'C-1203', 'C-1204',\n",
       "       'C-1205', 'C-1206', 'C-1207', 'C-1208', 'C-1209', 'C-1210',\n",
       "       'C-1211', 'C-1212', 'C-1213', 'C-1214', 'C-1215', 'C-1216',\n",
       "       'C-1217', 'C-1218', 'C-1219', 'C-1220', 'C-1221', 'C-1222',\n",
       "       'C-1223', 'C-1224', 'C-1225', 'C-1226', 'C-1227', 'C-1228',\n",
       "       'C-1229', 'C-1230', 'C-1231', 'C-1232', 'C-1233', 'C-1234',\n",
       "       'C-1235', 'C-1236', 'C-1237', 'C-1238', 'C-1239', 'C-1240',\n",
       "       'C-1241', 'C-1242', 'C-1243', 'C-1244', 'C-1245', 'C-1246',\n",
       "       'C-1247', 'C-1248', 'C-1249', 'C-1250', 'C-1251', 'C-1252',\n",
       "       'C-1253', 'C-1254', 'C-1255', 'C-1256', 'C-1257', 'C-1258',\n",
       "       'C-1259', 'C-1260', 'C-1261', 'C-1262', 'C-1263', 'C-1264',\n",
       "       'C-1265', 'C-1266', 'C-1267', 'C-1268', 'C-1269', 'C-1270',\n",
       "       'C-1271', 'C-1272', 'C-1273', 'C-1274', 'C-1275', 'C-1276',\n",
       "       'C-1277', 'C-1278', 'C-1279', 'C-1280', 'C-1281', 'C-1282',\n",
       "       'C-1283', 'C-1284', 'C-1285', 'C-1286', 'C-1287', 'C-1288',\n",
       "       'C-1289', 'C-1290', 'C-1291', 'C-1292', 'C-1293', 'C-1294',\n",
       "       'C-1295', 'C-1296', 'C-1297', 'C-1298', 'C-1299', 'C-1300',\n",
       "       'C-1301', 'C-1302', 'C-1303', 'C-1304', 'C-1305', 'C-1306',\n",
       "       'C-1307', 'C-1308', 'C-1309', 'C-1310', 'C-1311', 'C-1312',\n",
       "       'C-1313', 'C-1314', 'C-1315', 'C-1316', 'C-1317', 'C-1318',\n",
       "       'C-1319', 'C-1320', 'C-1321', 'C-1322', 'C-1323', 'C-1324',\n",
       "       'C-1325', 'C-1326', 'C-1327', 'C-1328', 'C-1329', 'C-1330',\n",
       "       'C-1331', 'C-1332', 'C-1333', 'C-1334', 'C-1335', 'C-1336',\n",
       "       'C-1337', 'C-1338', 'C-1339', 'C-1340', 'C-1341', 'C-1342',\n",
       "       'C-1343', 'C-1344', 'C-1345', 'C-1346', 'C-1347', 'C-1348',\n",
       "       'C-1349', 'C-1350', 'C-1351', 'C-1352', 'C-1353', 'C-1354',\n",
       "       'C-1355', 'C-1356', 'C-1357', 'C-1358', 'C-1359', 'C-1360',\n",
       "       'C-1361', 'C-1362', 'C-1363', 'C-1364', 'C-1365', 'C-1366',\n",
       "       'C-1367', 'C-1368', 'C-1369', 'C-1370', 'C-1371', 'C-1372',\n",
       "       'C-1373', 'C-1374', 'C-1375', 'C-1376', 'C-1377', 'C-1378',\n",
       "       'C-1379', 'C-1380', 'C-1381', 'C-1382', 'C-1383', 'C-1384',\n",
       "       'C-1385', 'C-1386', 'C-1387', 'C-1388', 'C-1389', 'C-1390',\n",
       "       'C-1391', 'C-1392', 'C-1393', 'C-1394', 'C-1395', 'C-1396',\n",
       "       'C-1397', 'C-1398', 'C-1399', 'C-1400', 'C-1401', 'C-1402',\n",
       "       'C-1403', 'C-1404', 'C-1405', 'C-1406', 'C-1407', 'C-1408',\n",
       "       'C-1409', 'C-1410', 'C-1411', 'C-1412', 'C-1413', 'C-1414',\n",
       "       'C-1415', 'C-1416', 'C-1417', 'C-1418', 'C-1419', 'C-1420',\n",
       "       'C-1421', 'C-1422', 'C-1423', 'C-1424', 'C-1425', 'C-1426',\n",
       "       'C-1427', 'C-1428', 'C-1429', 'C-1430', 'C-1431', 'C-1432',\n",
       "       'C-1433', 'C-1434', 'C-1435', 'C-1436', 'C-1437', 'C-1438',\n",
       "       'C-1439', 'C-1440', 'C-1441', 'C-1442', 'C-1443', 'C-1444',\n",
       "       'C-1445', 'C-1446', 'C-1447', 'C-1448', 'C-1449', 'C-1450',\n",
       "       'C-1451', 'C-1452', 'C-1453', 'C-1454', 'C-1455', 'C-1456',\n",
       "       'C-1457', 'C-1458', 'C-1459', 'C-1460', 'C-1461', 'C-1462',\n",
       "       'C-1463', 'C-1464', 'C-1465', 'C-1466', 'C-1467', 'C-1468',\n",
       "       'C-1469', 'C-1470', 'C-1471', 'C-1472', 'C-1473', 'C-1474',\n",
       "       'C-1475', 'C-1476', 'C-1477', 'C-1478', 'C-1479', 'C-1480',\n",
       "       'C-1481', 'C-1482', 'C-1483', 'C-1484', 'C-1485', 'C-1486',\n",
       "       'C-1487', 'C-1488', 'C-1489', 'C-1490', 'C-1491', 'C-1492',\n",
       "       'C-1493', 'C-1494', 'C-1495', 'C-1496', 'C-1497', 'C-1498',\n",
       "       'C-1499', 'C-1500'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=test_df.index.to_numpy()\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute\n",
    "\n",
    "- NA: fill with median\n",
    "\n",
    "## Categorical\n",
    "\n",
    "- 0, 1, 2 -> {low, medium, high}\n",
    "\n",
    "## Labels\n",
    "\n",
    "{-1, 1} -> {0, 1}\n",
    "\n",
    "## Feature selection\n",
    "\n",
    "Keep features with highest variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "K = 1200\n",
    "\n",
    "labels = train_df['label']\n",
    "train_df['label'][labels == -1] = 0\n",
    "train_modif_df = train_df.copy()\n",
    "train_modif_df = train_modif_df.drop(\"label\", axis=1)\n",
    "\n",
    "train_modif_df = train_modif_df.replace({\"low\": 0, \"medium\":1, \"high\": 2})\n",
    "train_modif_df.fillna(train_modif_df.median(), inplace=True)\n",
    "X_df=train_modif_df.to_numpy()\n",
    "\n",
    "variances = sorted([(np.var(X_df[:, i]), i) for i in range(X_df.shape[1])], reverse=True)\n",
    "k_bests = [j for i,j in variances[:K]]\n",
    "\n",
    "X_df = X_df[:, k_bests]\n",
    "\n",
    "testtab = testtab[:, k_bests]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1CF</th>\n",
       "      <th>A2M-AS1</th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>A2ML1-AS1</th>\n",
       "      <th>A2ML1-AS2</th>\n",
       "      <th>A3GALT2</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>A4GNT</th>\n",
       "      <th>AACS</th>\n",
       "      <th>...</th>\n",
       "      <th>ZSWIM8-AS1</th>\n",
       "      <th>ZSWIM9</th>\n",
       "      <th>ZUP1</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11A</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>hsa-mir-423</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-5</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34979 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1BG  A1CF  A2M-AS1  A2ML1  A2ML1-AS1  A2ML1-AS2  A3GALT2  A4GALT  A4GNT  \\\n",
       "C-1   0.0   0.0        0    0.0          0        0.0      0.0     0.0    0.0   \n",
       "C-2   0.0   0.0        2    0.0          0        0.0      0.0     0.0    0.0   \n",
       "C-3   0.0   0.0        0    0.0          0        0.0      0.0     0.0    0.0   \n",
       "C-4   0.0   0.0        0    0.0          0        0.0      0.0     0.0    0.0   \n",
       "C-5  23.0   0.0        0    0.0          0        0.0      0.0     0.0    0.0   \n",
       "\n",
       "     AACS  ...  ZSWIM8-AS1  ZSWIM9  ZUP1  ZXDA  ZXDB  ZXDC  ZYG11A  ZYG11B  \\\n",
       "C-1   0.0  ...         0.0     0.0     0   0.0   0.0   0.0     0.0     0.0   \n",
       "C-2   0.0  ...         0.0     0.0     0   0.0   0.0   0.0     0.0     0.0   \n",
       "C-3   0.0  ...         0.0     0.0     0  19.0   1.0   0.0     0.0     0.0   \n",
       "C-4   0.0  ...         0.0     0.0     0   0.0   0.0   0.0     0.0     0.0   \n",
       "C-5   0.0  ...         0.0     0.0     0   0.0   0.0   0.0     0.0     0.0   \n",
       "\n",
       "     ZZEF1  hsa-mir-423  \n",
       "C-1      1          0.0  \n",
       "C-2      0          0.0  \n",
       "C-3      0          0.0  \n",
       "C-4      0          0.0  \n",
       "C-5      0          0.0  \n",
       "\n",
       "[5 rows x 34979 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_modif_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_df[0])\n",
    "len(testtab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathm\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "C:\\Users\\mathm\\Anaconda3\\lib\\site-packages\\distributed\\config.py:63: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config.update(yaml.load(text) or {})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 587, 1: 587})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathm\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: BCR boost=0.7300156268782305\n",
      "Resampled dataset shape Counter({0: 579, 1: 579})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathm\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: BCR boost=0.6970654033425451\n",
      "Resampled dataset shape Counter({0: 580, 1: 580})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathm\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: BCR boost=0.7416839916839917\n",
      "Resampled dataset shape Counter({0: 578, 1: 578})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathm\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: BCR boost=0.8\n",
      "Resampled dataset shape Counter({0: 588, 1: 588})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathm\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: BCR boost=0.7535714285714286\n",
      "Average BCR boost:0.7444672900952392\n",
      "std :0.03355682760410789\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE \n",
    "import lightgbm as lgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from collections import Counter\n",
    "import xgboost as XGBClassifier\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "X, y = X_df, labels.values\n",
    "i = 0\n",
    "\n",
    "scores = []\n",
    "\n",
    "max_score = 0\n",
    "\n",
    "\n",
    "for train_idx, test_idx in kf.split(X, y):\n",
    "    \n",
    "    X_tra, y_tra = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "    sm=SMOTE(k_neighbors=15)\n",
    "    X_train, y_train = sm.fit_resample(X_tra, y_tra)\n",
    "\n",
    "    print('Resampled dataset shape %s' % Counter(y_train))\n",
    "    model = lgb.LGBMClassifier(boosting_type='dart' ,num_iterations=400,learning_rate=0.05,num_leaves=127,n_estimators=50)\n",
    "    clf=AdaBoostClassifier(n_estimators=202,learning_rate=0.9)\n",
    "    clf2 = GradientBoostingClassifier(n_estimators=202,loss='exponential',min_samples_split=3,min_samples_leaf=5,max_features='auto',learning_rate=0.9)\n",
    "    eclf1 = VotingClassifier(estimators=[('ab', clf), ('gb', clf2),('lgb',model)], voting='soft').fit(X_train, y_train)\n",
    "    y_pred = eclf1.predict(X_test)\n",
    "    score = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    scores.append(score)\n",
    "    print(f\"Fold {i}: BCR boost={score}\")\n",
    "    i+=1\n",
    "    \n",
    "print(f\"Average BCR boost:{np.mean(scores)}\")\n",
    "print(f\"std :{np.std(scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathm\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0\n",
      " 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 1 0 1 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0]\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "X_tra, y_tra = X_df, labels.values\n",
    "sm=SMOTE(k_neighbors=15)\n",
    "X_train, y_train = sm.fit_resample(X_tra, y_tra)\n",
    "model = lgb.LGBMClassifier(boosting_type='dart' ,num_iterations=400,learning_rate=0.05,num_leaves=127,n_estimators=50)\n",
    "clf=AdaBoostClassifier(n_estimators=202,learning_rate=0.9)\n",
    "clf2 = GradientBoostingClassifier(n_estimators=202,loss='exponential',min_samples_split=3,min_samples_leaf=5,max_features='auto',learning_rate=0.9)\n",
    "eclf1 = VotingClassifier(estimators=[('ab', clf), ('gb', clf2),('lgb',model)], voting='soft').fit(X_train, y_train)\n",
    "y_pred = eclf1.predict(testtab)\n",
    "print(y_pred)\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1\n",
      " -1  1 -1 -1 -1 -1  1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1 -1 -1\n",
      " -1  1  1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1  1  1 -1 -1  1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1  1 -1  1\n",
      " -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1\n",
      "  1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1  1\n",
      " -1 -1 -1  1 -1 -1 -1 -1 -1  1  1  1 -1 -1 -1  1 -1 -1 -1  1 -1  1 -1  1\n",
      "  1  1 -1  1 -1 -1  1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1  1  1 -1  1  1 -1 -1  1  1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1  1 -1 -1  1 -1 -1  1 -1 -1 -1 -1\n",
      " -1 -1 -1  1 -1  1 -1 -1 -1 -1 -1  1  1 -1  1 -1 -1 -1 -1 -1 -1  1  1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1  1 -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1  1 -1 -1  1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1  1  1  1 -1 -1  1  1 -1 -1  1 -1  1 -1  1 -1 -1\n",
      "  1 -1 -1 -1 -1 -1 -1  1  1  1 -1 -1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1\n",
      " -1  1 -1  1  1  1 -1 -1 -1 -1 -1  1  1  1 -1 -1 -1 -1  1  1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1  1 -1 -1  1 -1 -1 -1 -1  1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1  1 -1  1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1  1 -1  1  1 -1 -1 -1 -1\n",
      " -1  1 -1 -1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1\n",
      " -1 -1 -1 -1 -1  1 -1 -1 -1  1 -1  1 -1  1 -1 -1 -1 -1 -1 -1]\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(len(y_pred)):\n",
    "    if (y_pred[i]==0):\n",
    "        y_pred[i]=-1\n",
    "    else:\n",
    "        count=count+1\n",
    "print(y_pred)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(data=y_pred,index=index)\n",
    "df_pred.to_csv('test_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
